{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d4a3e50",
   "metadata": {},
   "source": [
    "\n",
    "# Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77196f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "import openai  \n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca47ad3",
   "metadata": {},
   "source": [
    "# Step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d624f5a",
   "metadata": {},
   "source": [
    "## Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25cb9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = pd.read_csv(r'.\\data\\fx-historical-news.csv')\n",
    "bid = pd.read_csv(r'.\\data\\2324bid.csv')\n",
    "ask = pd.read_csv(r'.\\data\\2324ask.csv')\n",
    "event = pd.read_csv(r'.\\data\\forex_factory_cache.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cfed85",
   "metadata": {},
   "source": [
    "# Step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8232c1a9",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135e9b95",
   "metadata": {},
   "source": [
    "1. Prices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b5b1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bid['Gmt time'] = pd.to_datetime(bid['Gmt time'], format='%d.%m.%Y %H:%M:%S.%f')\n",
    "ask['Gmt time'] = pd.to_datetime(ask['Gmt time'], format='%d.%m.%Y %H:%M:%S.%f')\n",
    "bid.columns = [f\"Bid_{col}\" for col in bid.columns]\n",
    "ask.columns = [f\"Ask_{col}\" for col in ask.columns]\n",
    "prices = pd.merge(bid, ask, on='Gmt time')\n",
    "prices = prices.rename(columns={'Gmt time': 'Timestamp'})\n",
    "prices['Timestamp'] = prices['Timestamp'].dt.tz_localize(None)\n",
    "prices.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cff6de",
   "metadata": {},
   "source": [
    "2.Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55f3b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "event['DateTime'] = pd.to_datetime(event['DateTime'],utc=True)\n",
    "event['text'] = event.apply(\n",
    "    lambda row: f\"{row['Currency']} | {row['Impact']} | {row['Event']} | Actual: {row['Actual']} | Previous: {row['Previous']}\", \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "def round_to_nearest_hour(dt):\n",
    "    if dt.minute <= 30:\n",
    "        rounded_hour = dt.hour\n",
    "    else:\n",
    "        rounded_hour = (dt.hour + 1) % 24\n",
    "        if rounded_hour == 0:\n",
    "            dt = dt + pd.Timedelta(days=1)\n",
    "    return dt.replace(hour=rounded_hour, minute=0, second=0, microsecond=0)\n",
    "\n",
    "event['Timestamp'] = event['DateTime'].apply(round_to_nearest_hour)\n",
    "event = event[['Timestamp', 'text']]\n",
    "\n",
    "event['Timestamp'] = event['Timestamp'].dt.tz_localize(None)\n",
    "event = event[['Timestamp', 'text']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0e8860",
   "metadata": {},
   "source": [
    "3.News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e255531",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "    \n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    \n",
    "    cleaned_text = ' '.join(tokens)\n",
    "    \n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "news['cleaned_text'] = news['text'].apply(clean_text)\n",
    "news = news[['Timestamp', 'cleaned_text']]\n",
    "news = news.rename(columns={'cleaned_text': 'text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bdd134",
   "metadata": {},
   "outputs": [],
   "source": [
    "news['DateTime'] = pd.to_datetime(news['DateTime'])\n",
    "news['Timestamp'] = news['DateTime'].apply(round_to_nearest_hour)\n",
    "news['Timestamp'] = news['Timestamp'].dt.tz_localize(None)\n",
    "news = news[['Timestamp', 'text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393d9ab7",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8049f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices['target'] = ((prices['Bid_Close'] + prices['Ask_Close']) / 2).shift(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8553a492",
   "metadata": {},
   "source": [
    "## Creating Unique Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e48ae39",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_prepared = news[['Timestamp', 'text']].copy()\n",
    "news_prepared['source'] = 'news'\n",
    "event_prepared = event[['Timestamp', 'text']].copy()\n",
    "event_prepared['source'] = 'event'\n",
    "\n",
    "text_data = pd.concat([news_prepared, event_prepared], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f875c6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = text_data.merge(prices, on=\"Timestamp\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1f467d",
   "metadata": {},
   "source": [
    "# Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d36794",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7489f466",
   "metadata": {},
   "source": [
    "### FinBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef3f0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
    "finbert = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer, device=0, max_length=512)\n",
    "\n",
    "\n",
    "def get_sentiment_batch(merged_df, batch_size=32):\n",
    "    sentiments = []\n",
    "    \n",
    "    \n",
    "    for i in range(0, len(merged_df), batch_size):\n",
    "        \n",
    "        batch = merged_df.iloc[i:i+batch_size]['text'].tolist()\n",
    "        \n",
    "        \n",
    "        results = finbert(batch)\n",
    "        \n",
    "        \n",
    "        batch_sentiments = [result['label'] for result in results]\n",
    "        \n",
    "        \n",
    "        sentiments.extend(batch_sentiments)\n",
    "        \n",
    "    \n",
    "   \n",
    "    merged_df['sentiment'] = sentiments\n",
    "    return merged_df\n",
    "\n",
    "\n",
    "merged_df = get_sentiment_batch(merged_df)\n",
    "\n",
    "merged_df = merged_df.rename(columns={'sentiment': 'finbert_sent'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fef6872",
   "metadata": {},
   "source": [
    "## LLMs Throw Ollama API (LLaMA2, LLaMA3, Gemma3, Gemma_fx, Deep2, Mistral)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7f97ab",
   "metadata": {},
   "source": [
    "1. Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f36d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_sentiment_forex_pairs = '''You are a financial analyst AI specialized in the Forex market, particularly EUR/USD currency movements.\n",
    "\n",
    "You will be given a short text containing either economic news or event summaries relevant to the Forex market.\n",
    "\n",
    "Analyze the text and determine the overall sentiment it conveys about the EUR/USD pair, based on how such content typically affects the market.\n",
    "\n",
    "Respond using only one of the following labels:\n",
    "- Positive\n",
    "- Negative\n",
    "- Neutral\n",
    "\n",
    "Strictly follow these rules:\n",
    "- Do not explain or justify your answer.\n",
    "- Do not use full sentences.\n",
    "- Do not include any punctuation or extra words.\n",
    "- Only output one of the three labels above exactly as written.\n",
    "- Never respond with anything outside of those three labels.'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc880c8",
   "metadata": {},
   "source": [
    "2. Loading LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aa0485",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_base = \"http://localhost:11434/v1\"  \n",
    "openai.api_key = \"ollama3\"  \n",
    "\n",
    "def ask_llama3(input_content, system_prompt, deep_think=True):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"llama3.1:latest\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": input_content}\n",
    "        ]\n",
    "    )\n",
    "    response_text = response['choices'][0]['message']['content']\n",
    "    if print_log:\n",
    "        print(response_text)\n",
    "\n",
    "    \n",
    "    think_texts = re.findall(r'<think>(.*?)</think>', response_text, flags=re.DOTALL)\n",
    "    think_texts = \"\\n\\n\".join(think_texts).strip()\n",
    "    clean_response = re.sub(r'<think>.*?</think>', '', response_text, flags=re.DOTALL).strip()\n",
    "\n",
    "    return clean_response if not deep_think else (clean_response, think_texts)\n",
    "\n",
    "\n",
    "merged_df[['llama3.1_sent', 'llama3.1_THINK']] = merged_df['text'].apply(\n",
    "    lambda comment: ask_llama3(comment, system_prompt_sentiment_forex_pairs)\n",
    ").apply(pd.Series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0e1919",
   "metadata": {},
   "source": [
    "3. Creating LLMs features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9a6fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_map = {\"Positive\": 1, \"Neutral\": 0, \"Negative\": -1}\n",
    "merged_df[\"finbert_sentiment\"] = merged_df[\"finbert_sentiment\"].map(sentiment_map)\n",
    "merged_df[\"llama3.1_sent\"] = merged_df[\"llama3.1_sent\"].map(sentiment_map)\n",
    "merged_df[\"gemma3.12_sent\"] = merged_df[\"gemma3.12_sent\"].map(sentiment_map)\n",
    "merged_df[\"deep2_sent\"] = merged_df[\"deep2_sent\"].map(sentiment_map)\n",
    "merged_df[\"llama2_sent\"] = merged_df[\"llama2_sent\"].map(sentiment_map)\n",
    "merged_df[\"gemma_fx_sent\"] = merged_df[\"gemma_fx_sent\"].map(sentiment_map)\n",
    "merged_df[\"mistral7b_sent\"] = merged_df[\"mistral7b_sent\"].map(sentiment_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27677a86",
   "metadata": {},
   "source": [
    "4. Merge Dataset with LLMs Sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb8a082",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.drop(columns=['llama3.1_THINK', 'gemma3.12_THINK', 'deep2_THINK', 'llama2_THINK', 'gemma_fx_THINK', 'mistral7b_THINK'])\n",
    "\n",
    "merged_df = merged_df.groupby(\"Timestamp\", as_index=False).agg({\n",
    "    \"Bid_Close\": \"first\",\n",
    "    \"Ask_Close\": \"first\",\n",
    "    \"Mid_Close\": \"first\",\n",
    "    \"target\": \"first\",\n",
    "    \"finbert_sent\": \"mean\",\n",
    "    \"llama3.1_sent\": \"mean\",\n",
    "    \"gemma3.12_sent\": \"mean\",\n",
    "    \"deep2_sent\": \"mean\",\n",
    "    \"llama2_sent\": \"mean\",\n",
    "    \"gemma_fx_sent\": \"mean\",\n",
    "    \"mistral7b_sent\" : \"mean\"\n",
    "})\n",
    "\n",
    "\n",
    "merged_df = merged_df.round(4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096f3238",
   "metadata": {},
   "source": [
    "# Step 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25b5a97",
   "metadata": {},
   "source": [
    "1. Spliting Subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbd39fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(df, train_ratio=0.7, val_ratio=0.15):\n",
    "\n",
    "    data_len = len(df)\n",
    "    train_end = int(data_len * train_ratio)\n",
    "    val_end = int(data_len * (train_ratio + val_ratio))\n",
    "\n",
    "    train_df = df.iloc[:train_end]\n",
    "    val_df = df.iloc[train_end:val_end]\n",
    "    test_df = df.iloc[val_end:]\n",
    "\n",
    "    return train_df, val_df, test_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf49ca4",
   "metadata": {},
   "source": [
    "2. Feature Selection for each Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3771e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are baseline experiment columns and for sentiment analysis we will add sentiment column of each LLM\n",
    "df = merged_df.copy()\n",
    "df = df[['Bid_Open','Bid_High','Bid_Low','Bid_Close', 'Bid_Volume',\n",
    "          'Ask_Open','Ask_High','Ask_Low','Ask_Close','Ask_Volume','target']].copy()\n",
    "\n",
    "\n",
    "train_df, val_df, test_df = split_dataset(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c89fbd",
   "metadata": {},
   "source": [
    "3. Data Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c968a7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "train_scaled = scaler.fit_transform(train_df)\n",
    "val_scaled = scaler.transform(val_df)\n",
    "test_scaled = scaler.transform(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a75b49",
   "metadata": {},
   "source": [
    "4. Data Prepration for LSTM and GRU Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80943dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step = 48                                       # window size of 48, 72 and 96 hours\n",
    "\n",
    "\n",
    "def create_sequences(data, time_step=time_step):   \n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - time_step):\n",
    "        X.append(data[i:i + time_step, :-1])\n",
    "        y.append(data[i + time_step, -1])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "\n",
    "all_scaled = np.vstack([train_scaled, val_scaled, test_scaled])\n",
    "X_all, y_all = create_sequences(all_scaled, time_step)\n",
    "\n",
    "len_train = len(train_df) - time_step\n",
    "len_val = len(val_df) - time_step\n",
    "\n",
    "split1 = len_train - time_step\n",
    "split2 = len_val - time_step\n",
    "\n",
    "X_train, y_train = X_all[:split1], y_all[:split1]\n",
    "X_val, y_val     = X_all[split1:split2], y_all[split1:split2]\n",
    "X_test, y_test   = X_all[split2:], y_all[split2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8df784",
   "metadata": {},
   "source": [
    "5. Build and Train GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8718d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_gru_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(GRU(256, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(GRU(128, return_sequences=False))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-4), loss='mse')\n",
    "    return model\n",
    "\n",
    "early_stop = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "gru_model = build_gru_model((X_train.shape[1], X_train.shape[2]))\n",
    "gru_model.fit(X_train, y_train,\n",
    "              validation_data=(X_val, y_val),\n",
    "              epochs=50,\n",
    "              batch_size=128,\n",
    "              callbacks=[early_stop],\n",
    "              verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1d3052",
   "metadata": {},
   "source": [
    "6. Build and Train LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749397a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(256, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(128, return_sequences=False))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-4), loss='mse')\n",
    "    return model\n",
    "\n",
    "lstm_model = build_lstm_model((X_train.shape[1], X_train.shape[2]))\n",
    "lstm_model.fit(X_train, y_train,\n",
    "               validation_data=(X_val, y_val),\n",
    "               epochs=50,\n",
    "               batch_size=128,\n",
    "               callbacks=[early_stop],\n",
    "               verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0213b7b7",
   "metadata": {},
   "source": [
    "7. Evaluate GRU and LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d952f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y, name):\n",
    "    y_pred = model.predict(X)\n",
    "    y_true_scaled = y.reshape(-1, 1)\n",
    "    y_pred_scaled = y_pred.reshape(-1, 1)\n",
    "\n",
    "    pad_true = np.zeros((len(y_true_scaled), all_scaled.shape[1]))\n",
    "    pad_true[:, -1] = y_true_scaled.flatten()\n",
    "    pad_pred = np.zeros_like(pad_true)\n",
    "    pad_pred[:, -1] = y_pred_scaled.flatten()\n",
    "\n",
    "    y_true_real = scaler.inverse_transform(pad_true)[:, -1]\n",
    "    y_pred_real = scaler.inverse_transform(pad_pred)[:, -1]\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_true_real, y_pred_real))\n",
    "    mae = mean_absolute_error(y_true_real, y_pred_real)\n",
    "    mape = np.mean(np.abs((y_true_real - y_pred_real) / y_true_real)) * 100\n",
    "    r2 = r2_score(y_true_real, y_pred_real)\n",
    "\n",
    "    print(f\"{name} RMSE: {rmse:.5f}, MAE: {mae:.5f}, MAPE: {mape:.2f}%, R²: {r2:.4f}\")\n",
    "\n",
    "\n",
    "evaluate_model(gru_model, X_test, y_test, \"GRU\")\n",
    "evaluate_model(lstm_model, X_test, y_test, \"LSTM\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992bcf4e",
   "metadata": {},
   "source": [
    "8. Preparing Data for XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943bc7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step = 48                                      # window size of 48, 72 and 96 hours\n",
    "\n",
    "def create_lagged_features(X, y, n_lags=time_step):\n",
    "    X_lagged, y_lagged = [], []\n",
    "    for i in range(n_lags, len(X)):\n",
    "        X_lagged.append(X[i - n_lags:i].flatten())\n",
    "        y_lagged.append(y[i])\n",
    "    return np.array(X_lagged), np.array(y_lagged)\n",
    "\n",
    "X_all_lag, y_all_lag = create_lagged_features(X_all, y_all, n_lags=time_step)\n",
    "X_train_lag = X_all_lag[:split1 - time_step]\n",
    "y_train_lag = y_all_lag[:split1 - time_step]\n",
    "X_val_lag = X_all_lag[split1 - time_step:split2 - time_step]\n",
    "y_val_lag = y_all_lag[split1 - time_step:split2 - time_step]\n",
    "X_test_lag = X_all_lag[split2 - time_step:]\n",
    "y_test_lag = y_all_lag[split2 - time_step:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4ef82b",
   "metadata": {},
   "source": [
    "9. Build XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa2cc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    tree_method='hist',        \n",
    "    device='cuda',           \n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=4,\n",
    "    verbosity=1\n",
    ")\n",
    "\n",
    "xgb_model.fit(\n",
    "    X_train_lag, y_train_lag,\n",
    "    eval_set=[(X_val_lag, y_val_lag)],\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a2d6c5",
   "metadata": {},
   "source": [
    "10. Evaluating XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71e228e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred_xgb = xgb_model.predict(X_test_lag)\n",
    "\n",
    "\n",
    "target_scaler = MinMaxScaler()\n",
    "target_scaler.fit(train_df[['target']])\n",
    "y_test_real = target_scaler.inverse_transform(y_test_lag.reshape(-1, 1)).flatten()\n",
    "y_pred_real = target_scaler.inverse_transform(y_pred_xgb.reshape(-1, 1)).flatten()\n",
    "\n",
    "\n",
    "rmse_xgb = np.sqrt(mean_squared_error(y_test_real, y_pred_real))\n",
    "mae_xgb = mean_absolute_error(y_test_real, y_pred_real)\n",
    "mape_xgb = np.mean(np.abs((y_test_real - y_pred_real) / y_test_real)) * 100\n",
    "r2_xgb = r2_score(y_test_real, y_pred_real)\n",
    "\n",
    "\n",
    "print(f\"XGBoost RMSE: {rmse_xgb:.5f}, MAE: {mae_xgb:.5f}, MAPE: {mape_xgb:.2f}%, R2:{r2_xgb:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
